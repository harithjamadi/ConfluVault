import streamlit as st
from retriever import retrieve
from chatbot import prompt_local_llm
from pathlib import Path
from embedder import embed_and_save, INDEX_PATH

st.set_page_config(page_title="ConfluVault", page_icon="ğŸ“š")
st.title("ğŸ“š ConfluVault â€“ Ask Your Docs")

# Step 1: Ensure FAISS index file exists
index_file = INDEX_PATH / "index.faiss"
if not index_file.exists():
    with st.spinner("ğŸ”§ Embedding documents and building index..."):
        try:
            embed_and_save()
            st.success("âœ… Index built successfully!")
        except Exception as e:
            st.error(f"âŒ Failed to build index: {e}")
            st.stop()

# Step 2: User input
st.markdown("Ask a question based on your documents:")
query = st.text_input("ğŸ” Enter your question:")

# Alternative: Use st.chat_input() if you prefer modern UX (Streamlit >= 1.25)
# query = st.chat_input("Ask something...")

# Step 3: Handle query
if query:
    with st.spinner("ğŸ“– Retrieving relevant content..."):
        try:
            doc_tuples = retrieve(query)
            if not doc_tuples:
                st.warning("âš ï¸ No relevant documents found.")
                st.stop()
        except Exception as e:
            st.error(f"âŒ Retrieval error: {e}")
            st.stop()

    with st.spinner("ğŸ§  Generating answer with local LLM..."):
        try:
            response = prompt_local_llm(doc_tuples, query)
        except Exception as e:
            st.error(f"âŒ LLM error: {e}")
            st.stop()

    # Step 4: Display results
    st.markdown("### ğŸ§  Answer")
    st.write(response)

    st.markdown("### ğŸ“„ Sources")
    for filename, _ in doc_tuples:
        st.markdown(f"- `{filename}`")

# Optional: File upload interface for future enhancements
# st.sidebar.header("ğŸ“‚ Upload new documents")
# uploaded_files = st.sidebar.file_uploader("Add Markdown or Text files", type=["md", "txt"], accept_multiple_files=True)
